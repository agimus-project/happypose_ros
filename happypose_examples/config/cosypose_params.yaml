/**:
  ros__parameters:
    # Device to which the models will be loaded. Supported options are 'cpu' and 'cuda:x' where 'x' is the GPU number.
    device: $(var device)
    # Publish detected objects as markers to visualize detections in RViz
    visualization.publish_markers: true
    # Extended verbosity on info logs. Show logs with number of detections and more
    verbose_info_logs: true
    # Specifies whether to use depth images for pose refinement. If set to `true` all cameras are expected to provide depth images
    use_depth: false
    # Specifies which pose estimator to use in the pipeline
    pose_estimator_type: "cosypose"
    cosypose:
      # Name of BOP dataset, used to load specific weights and object models
      dataset_name: $(var dataset_name)
      # Type of neural network model to use. Available 'pbr'|'synth+real'
      model_type: $(var model_type)
      # Object renderer parameters
      renderer:
        # Specifies which renderer to use in the pipeline
        renderer_type: "panda3d"
        # Number of CPU cores to use during rendering
        n_workers: 8
      # Parameters expected on the runtime
      inference:
        # 2D image detection parameters
        detector:
          # Detection threshold of an object used by detector
          detection_th: 0.7
        # 3D pose estimation parameters
        pose_estimator:
          # Number of iterations for the refiner
          n_coarse_iterations: 1
          # Number of iterations for the coarse estimate
          n_refiner_iterations: 3
          # Labels of detected objects to keep. If not specyfied, all objects are kept
          # labels_to_keep:
          #   - "ycbv-obj_000001"
        icp:
          # Minimum number of matching depth points to consider detection valid
          n_min_points: 1000
          # Minimum clipping distance of depth point from the camera to be considered valid
          min_measured_depth: 0.2
          # Maximum clipping distance of depth point from the camera to be considered valid
          max_measured_depth: 5.0
          # Number of iterations of ICP algorithm
          iterations: 100
          # Controls the accuracy of registration at each iteration of ICP
          tolerance: 0.05
          # Robust outlier rejection is applied for robustness.
          # This value actually corresponds to the standard deviation coefficient.
          # Points with rejectionScale * &sigma are ignored during registration
          rejection_scale: 2.5
          # Number of pyramid levels to proceed. Deep pyramids increase speed but decrease accuracy.
          # Too coarse pyramids might have computational overhead on top of the inaccurate registrtaion.
          # This parameter should be chosen to optimize a balance. Typical values range from 4 to 10
          num_levels: 4
    # List of camera names to subscribe to. Those names are internal to happypose_ros node
    # and can be chosen arbitrarily as long as they are valid YAML keys to be used later
    camera_names: ["cam_1"]
    cameras:
      # Timeout, after which a frame from a camera is considered too old. Value '0.0' disables timeout
      timeout: 0.0
      # Minimum number of valid camera views to start pose estimation pipeline
      n_min_cameras: 1
      # Configuration of camera "cam_1" defined in "camera_names" param
      cam_1:
        # Consider the camera to be leading. If a camera is leading, its frame_id is used as a reference.
        # Only one camera can be leading, and it can't publish TF at the same time
        leading: true
        # Publish TF of a given camera relative to the leading camera
        publish_tf: false
        # Expect compressed image messages from given camera
        compressed: false
        # Delay [seconds] with which incoming messages can be synchronized.
        # Value corresponds to synchronization of messages at 23 Hz.
        time_sync_slop: 0.04
